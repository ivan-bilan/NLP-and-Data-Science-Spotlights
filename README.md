# NLP and Data Science GitHub Repository Spotlight
Daily spotlights of some underrated NLP and Data Science GitHub repositories.

#### Spotlight №1 (January 18, 2020)
Topic Modelling approach called CorexTopic: https://github.com/gregversteeg/corex_topic

CorexTopic, or to be more verbose, Anchored Correlation Explanation Topic Modeling is a form of topic modeling that you should use when you already more or less know the topics you are expecting to extract from the dataset. Using CorexTopic you can help the model make those topics more precise and elaborate by providing so-called anchor words. With this approach, your topic clusters will be more precise. Try it out, it's a huge time saver when it comes to Topic Modeling.

And since we are on the topic of Topic Modelling, also take a look at a similar approach called GuidedLDA: https://github.com/vi3k6i5/GuidedLDA

#### Spotlight №2 (January 19, 2020)
Keywords extraction library called YAKE: https://github.com/LIAAD/yake

When it comes to keyword extraction the first instinct of many NLP experts is to try TextRank or RAKE. If you want to expand your tool-set when doing keyword extraction, YAKE is a great way to get keywords quickly and without any training of ML models from any document. The repository also gives a really great overview of similar keyword extraction algorithms. Give it a try.

#### Spotlight №3 (January 20, 2020)
Transfer Learning library for NLP called FARM: https://github.com/deepset-ai/FARM

FARM builds upon the very successful Transformers package (https://github.com/huggingface/transformers) from Hugging Face and incorporates many existing models like BERT or XLNet. With FARM you can pre-train them easily for any downstream NLP tasks. FARM is great for some fast prototyping and proof-of-concept to show your PM that transfer learning is the way to go.

#### Spotlight №4 (January 21, 2020)
Today's pick is an Entity Matching approach that allows you to pre-train a Deep Learning model on any labeled data you might have: https://github.com/anhaidgroup/deepmatcher

Entity Matching has usually been done with a lot of hand-crafted features, Deep Matcher is one of the few DL based approaches to Entity Matching that actually work out of the box. If you have to match two databases and eliminate the duplicates, DeepMatcher is a great starting point.

#### Spotlight №5 (January 22, 2020)
Seq2seq library Headliner: https://github.com/as-ideas/headliner

Originally developed at Axel Springer by Christian Schäfer and Dat Tran, this library is a great way to train and deploy your seq2seq models. It includes Transformer based models that can be used for summarization. Originally created to generate a headline for a piece of news, it can be used for many other tasks as well. Headliner is a great tool to try out for anyone working on summarization or wants to expand their understanding of what the Transformer architecture is capable of. 

#### Spotlight №6 (January 23, 2020)
NLP library that incorporates many Deep Learning-based models into one easy to use package called gobbli: https://github.com/RTIInternational/gobbli

Its motto is 'Deep learning with text doesn't have to be scary.', and it fulfills the promise by delivering an easy to use interface that covers many NLP approaches. You can use this one for quick prototyping with ease, try it out!

#### Spotlight №7 (January 24, 2020)
Compendium of all latest impactful NLP papers from the top NLP conferences: https://github.com/soulbliss/NLP-conference-compendium

It comprises links to papers that have won the best paper and best demo awards at ACL and EMNLP conferences for the past few years and also links to various tutorials and eventually all other accepted papers. Great way to track the progress in NLP.

#### Spotlight №8 (January 25, 2020)
A library that enables data scientists and data engineers to write data related tests faster. It's called "great expectations": https://github.com/great-expectations/great_expectations

It has a collection of ready to use testing functions that will test you tabular data for various potential pitfalls that you as a developer might not have accounted for right away. You should try them out and add them to your integration tests to avoid any unpleasant surprises.

To go with that, also try out snorkel (https://github.com/snorkel-team/snorkel) to quickly generate some test data.

#### Spotlight №9 (January 26, 2020)
A package that let's you automatically extend your textual training data: https://github.com/makcedward/nlpaug

With "nlpaug" you can automatically regenerate a sentence and replace various words in it with synonyms, antonyms, misspelled varients and more. You can also generate similar sentences and change the context within them using Transformer based generator models. Great way to artificially augment your NLP data with meaningful examples and minimal effort.

#### Spotlight №10 (January 27, 2020)
A package for cleaning tabular data called PyJanitor: https://github.com/ericmjl/pyjanitor

PyJanitor gives you access to a lot of cleaning functions that can make your DataFrames more consistent. You automatically remove empty rows and columns, identify duplicate entries, encode categories as categorical data for faster processing and do various forms of data conversions, all within one package.

### Follow me for more content like this:
- LinkedIn: https://www.linkedin.com/in/ivan-bilan/
- Twitter: https://twitter.com/DemiourgosUA
- GitHub: https://github.com/ivan-bilan
- Medium (for non-tech content): https://medium.com/@demiourgosua/
